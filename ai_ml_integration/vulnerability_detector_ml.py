#!/usr/bin/env python3
"""
QuantumSentinel-Nexus AI/ML Vulnerability Detection System
Advanced ML-powered vulnerability detection using Hugging Face models
"""

import asyncio
import logging
import json
import re
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from pathlib import Path
import numpy as np
import torch
from datetime import datetime
import pickle
import sqlite3
from concurrent.futures import ThreadPoolExecutor
import requests
import base64

# Hugging Face and ML imports
from transformers import (
    AutoTokenizer, AutoModel, AutoModelForSequenceClassification,
    pipeline, BertTokenizer, BertForSequenceClassification,
    RobertaTokenizer, RobertaForSequenceClassification
)
from sentence_transformers import SentenceTransformer
import tensorflow as tf
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

@dataclass
class VulnerabilityPrediction:
    """ML-based vulnerability prediction result"""
    vulnerability_type: str
    confidence_score: float
    severity: str
    cwe_id: Optional[str]
    description: str
    evidence: List[str]
    attack_vector: str
    remediation: str
    ml_model_used: str
    prediction_timestamp: datetime
    risk_score: float
    false_positive_probability: float

@dataclass
class MLModelMetrics:
    """Model performance metrics"""
    model_name: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    inference_time_ms: float
    last_updated: datetime

class VulnerabilityDetectorML:
    """Advanced ML-powered vulnerability detection system"""

    def __init__(self, config_path: str = None):
        self.logger = logging.getLogger(__name__)
        self.config = self._load_config(config_path)
        self.models = {}
        self.tokenizers = {}
        self.pipelines = {}
        self.model_metrics = {}
        self.vulnerability_database = VulnerabilityDatabase()
        self.executor = ThreadPoolExecutor(max_workers=8)

        # Initialize ML models
        asyncio.create_task(self._initialize_models())

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load ML model configuration"""
        default_config = {
            "models": {
                "code_vulnerability": "microsoft/codebert-base",
                "sql_injection": "huggingface/CodeBERTa-small-v1",
                "xss_detection": "distilbert-base-uncased",
                "auth_bypass": "roberta-base",
                "api_security": "microsoft/GraphCodeBERT-base",
                "business_logic": "sentence-transformers/all-MiniLM-L6-v2",
                "zero_day": "microsoft/DialoGPT-medium"
            },
            "thresholds": {
                "high_confidence": 0.85,
                "medium_confidence": 0.65,
                "low_confidence": 0.45
            },
            "cache_models": True,
            "max_sequence_length": 512,
            "batch_size": 16,
            "enable_gpu": True
        }

        if config_path and Path(config_path).exists():
            with open(config_path, 'r') as f:
                user_config = json.load(f)
                default_config.update(user_config)

        return default_config

    async def _initialize_models(self):
        """Initialize all ML models for vulnerability detection"""
        self.logger.info("Initializing ML models for vulnerability detection...")

        try:
            # Code vulnerability detection model
            await self._load_code_vulnerability_model()

            # SQL injection detection model
            await self._load_sql_injection_model()

            # XSS detection model
            await self._load_xss_detection_model()

            # Authentication bypass model
            await self._load_auth_bypass_model()

            # API security model
            await self._load_api_security_model()

            # Business logic vulnerability model
            await self._load_business_logic_model()

            # Zero-day discovery model
            await self._load_zero_day_model()

            # Custom ensemble models
            await self._load_ensemble_models()

            self.logger.info("All ML models initialized successfully")

        except Exception as e:
            self.logger.error(f"Error initializing ML models: {e}")
            raise

    async def _load_code_vulnerability_model(self):
        """Load CodeBERT model for general code vulnerability detection"""
        model_name = self.config["models"]["code_vulnerability"]

        try:
            self.tokenizers["code_vuln"] = AutoTokenizer.from_pretrained(model_name)
            self.models["code_vuln"] = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=10,  # Support for 10 different vulnerability types
                cache_dir="./models/cache"
            )

            # Create pipeline for easier inference
            self.pipelines["code_vuln"] = pipeline(
                "text-classification",
                model=self.models["code_vuln"],
                tokenizer=self.tokenizers["code_vuln"],
                device=0 if torch.cuda.is_available() and self.config["enable_gpu"] else -1
            )

            self.logger.info("Code vulnerability model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading code vulnerability model: {e}")
            # Fallback to basic pattern matching
            self._initialize_fallback_code_detector()

    async def _load_sql_injection_model(self):
        """Load specialized SQL injection detection model"""
        try:
            # Custom fine-tuned model for SQL injection detection
            self.models["sql_injection"] = self._create_sql_injection_classifier()

            # Load pre-trained patterns
            self.sql_patterns = self._load_sql_injection_patterns()

            self.logger.info("SQL injection model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading SQL injection model: {e}")

    async def _load_xss_detection_model(self):
        """Load XSS detection model"""
        model_name = self.config["models"]["xss_detection"]

        try:
            self.tokenizers["xss"] = AutoTokenizer.from_pretrained(model_name)
            self.models["xss"] = AutoModelForSequenceClassification.from_pretrained(
                model_name,
                num_labels=3,  # XSS types: Reflected, Stored, DOM-based
                cache_dir="./models/cache"
            )

            # XSS-specific preprocessing pipeline
            self.pipelines["xss"] = self._create_xss_pipeline()

            self.logger.info("XSS detection model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading XSS model: {e}")

    async def _load_auth_bypass_model(self):
        """Load authentication bypass detection model"""
        try:
            # RoBERTa-based model for authentication flow analysis
            model_name = self.config["models"]["auth_bypass"]

            self.tokenizers["auth"] = RobertaTokenizer.from_pretrained(model_name)
            self.models["auth"] = RobertaForSequenceClassification.from_pretrained(
                model_name,
                num_labels=5,  # Different auth bypass types
                cache_dir="./models/cache"
            )

            # Authentication flow analyzer
            self.auth_flow_analyzer = AuthenticationFlowAnalyzer()

            self.logger.info("Authentication bypass model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading auth bypass model: {e}")

    async def _load_api_security_model(self):
        """Load API security assessment model"""
        try:
            model_name = self.config["models"]["api_security"]

            # GraphCodeBERT for API endpoint analysis
            self.models["api_security"] = AutoModel.from_pretrained(
                model_name,
                cache_dir="./models/cache"
            )

            # API vulnerability classifier
            self.api_classifier = APIVulnerabilityClassifier()

            self.logger.info("API security model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading API security model: {e}")

    async def _load_business_logic_model(self):
        """Load business logic vulnerability detection model"""
        try:
            # Sentence transformer for semantic analysis
            model_name = self.config["models"]["business_logic"]
            self.models["business_logic"] = SentenceTransformer(model_name)

            # Business logic pattern database
            self.business_logic_patterns = BusinessLogicPatternDatabase()

            self.logger.info("Business logic model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading business logic model: {e}")

    async def _load_zero_day_model(self):
        """Load zero-day discovery model"""
        try:
            # Advanced pattern recognition for unknown vulnerabilities
            self.zero_day_detector = ZeroDayDetector()

            # Anomaly detection model
            self.anomaly_detector = IsolationForest(
                contamination=0.1,
                random_state=42
            )

            self.logger.info("Zero-day detection model loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading zero-day model: {e}")

    async def _load_ensemble_models(self):
        """Load ensemble models for improved accuracy"""
        try:
            # Vulnerability classification ensemble
            self.ensemble_classifier = VulnerabilityEnsembleClassifier()

            # Risk assessment model
            self.risk_assessor = RiskAssessmentModel()

            # False positive reducer
            self.fp_reducer = FalsePositiveReducer()

            self.logger.info("Ensemble models loaded successfully")

        except Exception as e:
            self.logger.error(f"Error loading ensemble models: {e}")

    async def analyze_target_ml(self, target_data: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Main ML-powered vulnerability analysis"""
        self.logger.info(f"Starting ML analysis for target: {target_data.get('url', 'Unknown')}")

        predictions = []

        try:
            # Extract features for ML analysis
            features = await self._extract_features(target_data)

            # Run parallel ML analyses
            tasks = [
                self._detect_code_vulnerabilities(features),
                self._detect_sql_injection(features),
                self._detect_xss_vulnerabilities(features),
                self._detect_auth_bypass(features),
                self._detect_api_vulnerabilities(features),
                self._detect_business_logic_flaws(features),
                self._detect_zero_day_patterns(features)
            ]

            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Combine results
            for result in results:
                if isinstance(result, list):
                    predictions.extend(result)
                elif isinstance(result, Exception):
                    self.logger.error(f"ML analysis error: {result}")

            # Apply ensemble filtering and ranking
            predictions = await self._apply_ensemble_filtering(predictions)

            # Calculate risk scores
            predictions = await self._calculate_risk_scores(predictions)

            # Reduce false positives
            predictions = await self._reduce_false_positives(predictions)

            self.logger.info(f"ML analysis completed. Found {len(predictions)} potential vulnerabilities")

            return predictions

        except Exception as e:
            self.logger.error(f"Error in ML analysis: {e}")
            return []

    async def _extract_features(self, target_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract features for ML models"""
        features = {
            "url": target_data.get("url", ""),
            "source_code": target_data.get("source_code", ""),
            "http_responses": target_data.get("http_responses", []),
            "api_endpoints": target_data.get("api_endpoints", []),
            "form_data": target_data.get("forms", []),
            "headers": target_data.get("headers", {}),
            "cookies": target_data.get("cookies", {}),
            "javascript": target_data.get("javascript", ""),
            "network_traffic": target_data.get("network_traffic", []),
            "authentication_flows": target_data.get("auth_flows", [])
        }

        # Additional feature engineering
        features["text_features"] = self._create_text_features(features)
        features["numerical_features"] = self._create_numerical_features(features)
        features["graph_features"] = self._create_graph_features(features)

        return features

    async def _detect_code_vulnerabilities(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect code-level vulnerabilities using ML"""
        predictions = []

        if not features.get("source_code"):
            return predictions

        try:
            code_chunks = self._chunk_code(features["source_code"])

            for chunk in code_chunks:
                # Tokenize and predict
                inputs = self.tokenizers["code_vuln"](
                    chunk,
                    truncation=True,
                    padding=True,
                    max_length=self.config["max_sequence_length"],
                    return_tensors="pt"
                )

                with torch.no_grad():
                    outputs = self.models["code_vuln"](**inputs)
                    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)

                    # Get top predictions
                    top_predictions = torch.topk(probabilities, k=3)

                    for i, (prob, class_id) in enumerate(zip(top_predictions.values[0], top_predictions.indices[0])):
                        if prob.item() > self.config["thresholds"]["low_confidence"]:
                            vulnerability = self._map_class_to_vulnerability(class_id.item(), prob.item())
                            vulnerability.evidence = [chunk]
                            vulnerability.ml_model_used = "CodeBERT"
                            predictions.append(vulnerability)

            return predictions

        except Exception as e:
            self.logger.error(f"Error in code vulnerability detection: {e}")
            return []

    async def _detect_sql_injection(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect SQL injection vulnerabilities"""
        predictions = []

        try:
            # Analyze form inputs
            for form in features.get("form_data", []):
                for input_field in form.get("inputs", []):
                    sql_risk = self._analyze_sql_injection_risk(input_field)
                    if sql_risk["risk_score"] > 0.5:
                        predictions.append(self._create_sql_injection_prediction(sql_risk))

            # Analyze URL parameters
            url_params = self._extract_url_parameters(features.get("url", ""))
            for param in url_params:
                sql_risk = self._analyze_sql_injection_risk(param)
                if sql_risk["risk_score"] > 0.5:
                    predictions.append(self._create_sql_injection_prediction(sql_risk))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in SQL injection detection: {e}")
            return []

    async def _detect_xss_vulnerabilities(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect XSS vulnerabilities using ML"""
        predictions = []

        try:
            # Analyze DOM elements and user inputs
            dom_elements = features.get("dom_elements", [])
            user_inputs = features.get("user_inputs", [])

            for element in dom_elements + user_inputs:
                xss_risk = await self._analyze_xss_risk(element)
                if xss_risk["confidence"] > self.config["thresholds"]["low_confidence"]:
                    predictions.append(self._create_xss_prediction(xss_risk))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in XSS detection: {e}")
            return []

    async def _detect_auth_bypass(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect authentication bypass vulnerabilities"""
        predictions = []

        try:
            auth_flows = features.get("authentication_flows", [])

            for flow in auth_flows:
                bypass_risk = await self._analyze_auth_bypass_risk(flow)
                if bypass_risk["confidence"] > self.config["thresholds"]["medium_confidence"]:
                    predictions.append(self._create_auth_bypass_prediction(bypass_risk))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in auth bypass detection: {e}")
            return []

    async def _detect_api_vulnerabilities(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect API security vulnerabilities"""
        predictions = []

        try:
            api_endpoints = features.get("api_endpoints", [])

            for endpoint in api_endpoints:
                api_risks = await self._analyze_api_security(endpoint)
                for risk in api_risks:
                    if risk["confidence"] > self.config["thresholds"]["low_confidence"]:
                        predictions.append(self._create_api_vulnerability_prediction(risk))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in API vulnerability detection: {e}")
            return []

    async def _detect_business_logic_flaws(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect business logic vulnerabilities using semantic analysis"""
        predictions = []

        try:
            # Analyze business workflows and logic flows
            workflows = features.get("business_workflows", [])

            for workflow in workflows:
                logic_flaws = await self._analyze_business_logic(workflow)
                for flaw in logic_flaws:
                    if flaw["confidence"] > self.config["thresholds"]["medium_confidence"]:
                        predictions.append(self._create_business_logic_prediction(flaw))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in business logic detection: {e}")
            return []

    async def _detect_zero_day_patterns(self, features: Dict[str, Any]) -> List[VulnerabilityPrediction]:
        """Detect potential zero-day vulnerabilities using anomaly detection"""
        predictions = []

        try:
            # Extract behavioral patterns
            patterns = self._extract_behavioral_patterns(features)

            # Anomaly detection
            anomalies = self.zero_day_detector.detect_anomalies(patterns)

            for anomaly in anomalies:
                if anomaly["anomaly_score"] > 0.7:
                    predictions.append(self._create_zero_day_prediction(anomaly))

            return predictions

        except Exception as e:
            self.logger.error(f"Error in zero-day detection: {e}")
            return []

    def _create_text_features(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Create text-based features for ML models"""
        text_features = {}

        # Combine all text content
        combined_text = " ".join([
            features.get("source_code", ""),
            features.get("javascript", ""),
            str(features.get("headers", {})),
            str(features.get("form_data", []))
        ])

        # TF-IDF features
        if hasattr(self, 'tfidf_vectorizer'):
            text_features["tfidf"] = self.tfidf_vectorizer.transform([combined_text])

        # Text statistics
        text_features["char_count"] = len(combined_text)
        text_features["word_count"] = len(combined_text.split())
        text_features["line_count"] = combined_text.count('\n')

        # Security-relevant pattern counts
        text_features["sql_keywords"] = len(re.findall(r'\b(SELECT|INSERT|UPDATE|DELETE|UNION|OR|AND)\b', combined_text, re.IGNORECASE))
        text_features["script_tags"] = len(re.findall(r'<script[^>]*>', combined_text, re.IGNORECASE))
        text_features["eval_calls"] = len(re.findall(r'\beval\s*\(', combined_text, re.IGNORECASE))

        return text_features

    def _create_numerical_features(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Create numerical features for ML models"""
        numerical_features = {}

        # Response time features
        response_times = [r.get("response_time", 0) for r in features.get("http_responses", [])]
        if response_times:
            numerical_features["avg_response_time"] = np.mean(response_times)
            numerical_features["max_response_time"] = np.max(response_times)
            numerical_features["response_time_variance"] = np.var(response_times)

        # Form complexity
        forms = features.get("form_data", [])
        numerical_features["form_count"] = len(forms)
        numerical_features["total_input_fields"] = sum(len(form.get("inputs", [])) for form in forms)

        # API endpoint features
        api_endpoints = features.get("api_endpoints", [])
        numerical_features["api_endpoint_count"] = len(api_endpoints)
        numerical_features["unique_http_methods"] = len(set(ep.get("method", "GET") for ep in api_endpoints))

        return numerical_features

    def _create_graph_features(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Create graph-based features for complex relationship analysis"""
        graph_features = {}

        # Authentication flow graph complexity
        auth_flows = features.get("authentication_flows", [])
        if auth_flows:
            graph_features["auth_flow_complexity"] = self._calculate_flow_complexity(auth_flows)

        # API dependency graph
        api_endpoints = features.get("api_endpoints", [])
        if api_endpoints:
            graph_features["api_dependency_score"] = self._calculate_api_dependencies(api_endpoints)

        return graph_features

class VulnerabilityDatabase:
    """ML-enhanced vulnerability pattern database"""

    def __init__(self, db_path: str = "vulnerabilities.db"):
        self.db_path = db_path
        self._initialize_database()

    def _initialize_database(self):
        """Initialize SQLite database for vulnerability patterns"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerability_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_hash TEXT UNIQUE,
                vulnerability_type TEXT,
                confidence_score REAL,
                pattern_data TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ml_model_cache (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT,
                input_hash TEXT,
                prediction_result TEXT,
                confidence_score REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        conn.commit()
        conn.close()

class AuthenticationFlowAnalyzer:
    """Specialized authentication flow analysis"""

    def __init__(self):
        self.flow_patterns = self._load_auth_patterns()

    def _load_auth_patterns(self) -> Dict[str, Any]:
        """Load known authentication bypass patterns"""
        return {
            "sql_injection_auth": {
                "pattern": r"(admin['\"]?\s*(?:or|OR)\s*['\"]?1['\"]?\s*=\s*['\"]?1)",
                "confidence": 0.9
            },
            "jwt_none_algorithm": {
                "pattern": r"algorithm['\"]?\s*:\s*['\"]none['\"]",
                "confidence": 0.85
            },
            "session_fixation": {
                "pattern": r"session_id.*=.*['\"][^'\"]+['\"]",
                "confidence": 0.7
            }
        }

class APIVulnerabilityClassifier:
    """API-specific vulnerability classification"""

    def __init__(self):
        self.api_patterns = self._initialize_api_patterns()

    def _initialize_api_patterns(self) -> Dict[str, Any]:
        """Initialize API vulnerability patterns"""
        return {
            "mass_assignment": {
                "indicators": ["user_id", "admin", "role", "permissions"],
                "confidence_threshold": 0.8
            },
            "broken_authorization": {
                "indicators": ["user_id", "account_id", "profile_id"],
                "confidence_threshold": 0.75
            }
        }

class BusinessLogicPatternDatabase:
    """Business logic vulnerability pattern database"""

    def __init__(self):
        self.patterns = self._load_business_logic_patterns()

    def _load_business_logic_patterns(self) -> Dict[str, Any]:
        """Load business logic vulnerability patterns"""
        return {
            "price_manipulation": {
                "patterns": ["price", "amount", "total", "cost"],
                "contexts": ["checkout", "payment", "cart", "order"]
            },
            "workflow_bypass": {
                "patterns": ["step", "stage", "phase", "state"],
                "contexts": ["approval", "verification", "confirmation"]
            }
        }

class ZeroDayDetector:
    """Advanced zero-day vulnerability detection"""

    def __init__(self):
        self.anomaly_patterns = []
        self.behavioral_baselines = {}

    def detect_anomalies(self, patterns: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Detect anomalous patterns that might indicate zero-day vulnerabilities"""
        anomalies = []

        # Implement sophisticated anomaly detection logic
        for pattern_name, pattern_data in patterns.items():
            anomaly_score = self._calculate_anomaly_score(pattern_data)
            if anomaly_score > 0.7:
                anomalies.append({
                    "pattern_name": pattern_name,
                    "anomaly_score": anomaly_score,
                    "pattern_data": pattern_data
                })

        return anomalies

    def _calculate_anomaly_score(self, pattern_data: Any) -> float:
        """Calculate anomaly score for pattern data"""
        # Placeholder implementation
        return 0.5

class VulnerabilityEnsembleClassifier:
    """Ensemble classifier for improved vulnerability detection accuracy"""

    def __init__(self):
        self.classifiers = []
        self.weights = []

    def predict(self, features: Dict[str, Any]) -> Dict[str, float]:
        """Ensemble prediction combining multiple models"""
        predictions = {}

        # Combine predictions from multiple models
        for classifier, weight in zip(self.classifiers, self.weights):
            pred = classifier.predict(features)
            for vuln_type, confidence in pred.items():
                if vuln_type not in predictions:
                    predictions[vuln_type] = 0
                predictions[vuln_type] += confidence * weight

        return predictions

class RiskAssessmentModel:
    """Advanced risk assessment using ML"""

    def __init__(self):
        self.risk_factors = self._initialize_risk_factors()

    def _initialize_risk_factors(self) -> Dict[str, float]:
        """Initialize risk factor weights"""
        return {
            "exploitability": 0.3,
            "impact": 0.4,
            "likelihood": 0.2,
            "detectability": 0.1
        }

    def calculate_risk_score(self, vulnerability: VulnerabilityPrediction) -> float:
        """Calculate comprehensive risk score"""
        # Implement risk calculation logic
        base_score = vulnerability.confidence_score
        severity_multiplier = {"critical": 1.0, "high": 0.8, "medium": 0.6, "low": 0.3}.get(vulnerability.severity.lower(), 0.5)

        return base_score * severity_multiplier

class FalsePositiveReducer:
    """ML-based false positive reduction"""

    def __init__(self):
        self.fp_model = None
        self._train_fp_model()

    def _train_fp_model(self):
        """Train false positive reduction model"""
        # Load training data and train model
        pass

    def predict_false_positive(self, vulnerability: VulnerabilityPrediction) -> float:
        """Predict probability that vulnerability is a false positive"""
        # Implement FP prediction logic
        return 0.1  # Placeholder

# Export main classes
__all__ = [
    'VulnerabilityDetectorML',
    'VulnerabilityPrediction',
    'MLModelMetrics'
]